{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7155103,"sourceType":"datasetVersion","datasetId":4131944},{"sourceId":7414349,"sourceType":"datasetVersion","datasetId":4313035},{"sourceId":7414421,"sourceType":"datasetVersion","datasetId":4313091},{"sourceId":7420846,"sourceType":"datasetVersion","datasetId":4317470},{"sourceId":7435780,"sourceType":"datasetVersion","datasetId":4327530},{"sourceId":4298,"sourceType":"modelInstanceVersion","modelInstanceId":3093}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Install","metadata":{}},{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git \n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git\n!pip install -q datasets\n!pip install numpy==1.22.0\n!pip install gensim\n!pip install pydantic==1.8.1\n!pip install openai\n!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2024-01-19T12:39:46.917610Z","iopub.execute_input":"2024-01-19T12:39:46.917956Z","iopub.status.idle":"2024-01-19T12:43:02.209901Z","shell.execute_reply.started":"2024-01-19T12:39:46.917923Z","shell.execute_reply":"2024-01-19T12:43:02.208686Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting numpy==1.22.0\n  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.24.3\n    Uninstalling numpy-1.24.3:\n      Successfully uninstalled numpy-1.24.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nchex 0.1.84 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ninequality 1.0.1 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nlibrosa 0.10.1 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\nspglm 1.1.0 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\nspreg 1.4.2 requires numpy>=1.23, but you have numpy 1.22.0 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.22.0\nRequirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.2)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.22.0)\nRequirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.11.3)\nRequirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (6.3.0)\nCollecting pydantic==1.8.1\n  Downloading pydantic-1.8.1-py3-none-any.whl (125 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.8.1) (4.5.0)\nInstalling collected packages: pydantic\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.12\n    Uninstalling pydantic-1.10.12:\n      Successfully uninstalled pydantic-1.10.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nconfection 0.1.3 requires pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\nfastapi 0.101.1 requires pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\nspacy 3.7.2 requires pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\nthinc 8.2.1 requires pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\nweasel 0.3.4 requires pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4, but you have pydantic 1.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pydantic-1.8.1\nCollecting openai\n  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/f1/d8/590a68d390501faf48f4e57b098076df02afd003ac880f50d3b0704f7773/openai-1.8.0-py3-none-any.whl.metadata\n  Downloading openai-1.8.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (3.7.1)\nCollecting distro<2,>=1.7.0 (from openai)\n  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting httpx<1,>=0.23.0 (from openai)\n  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\nCollecting pydantic<3,>=1.9.0 (from openai)\n  Obtaining dependency information for pydantic<3,>=1.9.0 from https://files.pythonhosted.org/packages/dd/b7/9aea7ee6c01fe3f3c03b8ca3c7797c866df5fecece9d6cb27caa138db2e2/pydantic-2.5.3-py3-none-any.whl.metadata\n  Downloading pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\nCollecting typing-extensions<5,>=4.7 (from openai)\n  Obtaining dependency information for typing-extensions<5,>=4.7 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\n  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\nCollecting pydantic-core==2.14.6 (from pydantic<3,>=1.9.0->openai)\n  Obtaining dependency information for pydantic-core==2.14.6 from https://files.pythonhosted.org/packages/90/28/3c6843e6b203999be2660d3f114be196f2182dcac533dc764ad320c9184d/pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nDownloading openai-1.8.0-py3-none-any.whl (222 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.3/222.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\nDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\nInstalling collected packages: typing-extensions, httpcore, distro, pydantic-core, httpx, pydantic, openai\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.5.0\n    Uninstalling typing_extensions-4.5.0:\n      Successfully uninstalled typing_extensions-4.5.0\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.10.1\n    Uninstalling pydantic_core-2.10.1:\n      Successfully uninstalled pydantic_core-2.10.1\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.8.1\n    Uninstalling pydantic-1.8.1:\n      Successfully uninstalled pydantic-1.8.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nchex 0.1.84 requires numpy>=1.24.1, but you have numpy 1.22.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\nlibrosa 0.10.1 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\ntensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflow-probability 0.21.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.5.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed distro-1.9.0 httpcore-1.0.2 httpx-0.26.0 openai-1.8.0 pydantic-2.4.2 pydantic-core-2.14.6 typing-extensions-4.7.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Imports + Daten","metadata":{}},{"cell_type":"code","source":"import transformers\nimport os\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport numpy as np\nimport pandas as pd\nfrom openai import OpenAI\nfrom gensim.models import KeyedVectors\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport random\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-01-19T12:43:02.212099Z","iopub.execute_input":"2024-01-19T12:43:02.212416Z","iopub.status.idle":"2024-01-19T12:43:20.363404Z","shell.execute_reply.started":"2024-01-19T12:43:02.212388Z","shell.execute_reply":"2024-01-19T12:43:20.362410Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T12:43:20.364660Z","iopub.execute_input":"2024-01-19T12:43:20.365131Z","iopub.status.idle":"2024-01-19T12:43:20.486395Z","shell.execute_reply.started":"2024-01-19T12:43:20.365104Z","shell.execute_reply":"2024-01-19T12:43:20.485516Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/llama-2/pytorch/7b-chat-hf/1/model.safetensors.index.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/config.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/model-00001-of-00002.safetensors\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/model-00002-of-00002.safetensors\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/pytorch_model-00002-of-00002.bin\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/README.md\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/USE_POLICY.md\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/tokenizer.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/tokenizer_config.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/pytorch_model.bin.index.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/LICENSE.txt\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/pytorch_model-00001-of-00002.bin\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/special_tokens_map.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/.gitattributes\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/tokenizer.model\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/added_tokens.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/generation_config.json\n/kaggle/input/finetuned-llama/model_7_4Entries/adapter_model.safetensors\n/kaggle/input/finetuned-llama/model_7_4Entries/training_args.bin\n/kaggle/input/finetuned-llama/model_7_4Entries/adapter_config.json\n/kaggle/input/finetuned-llama/model_7_4Entries/README.md\n/kaggle/input/finetuned-llama/wandb/run-20240116_085410-byo3drd7/run-byo3drd7.wandb\n/kaggle/input/finetuned-llama/wandb/run-20240116_085410-byo3drd7/logs/debug.log\n/kaggle/input/finetuned-llama/wandb/run-20240116_085410-byo3drd7/logs/debug-internal.log\n/kaggle/input/finetuned-llama/wandb/run-20240116_085410-byo3drd7/files/wandb-summary.json\n/kaggle/input/finetuned-llama/wandb/run-20240116_085410-byo3drd7/files/conda-environment.yaml\n/kaggle/input/finetuned-llama/wandb/run-20240116_085410-byo3drd7/files/config.yaml\n/kaggle/input/finetuned-llama/wandb/run-20240116_085410-byo3drd7/files/requirements.txt\n/kaggle/input/finetuned-llama/wandb/run-20240116_085410-byo3drd7/files/wandb-metadata.json\n/kaggle/input/finetuned-llama/halfinput/runs/Jan16_08-54-10_7c26c3325351/events.out.tfevents.1705395250.7c26c3325351.27.0\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1500/adapter_model.safetensors\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1500/trainer_state.json\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1500/training_args.bin\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1500/adapter_config.json\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1500/README.md\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1500/scheduler.pt\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1500/optimizer.pt\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1500/rng_state.pth\n/kaggle/input/finetuned-llama/halfinput/checkpoint-500/adapter_model.safetensors\n/kaggle/input/finetuned-llama/halfinput/checkpoint-500/trainer_state.json\n/kaggle/input/finetuned-llama/halfinput/checkpoint-500/training_args.bin\n/kaggle/input/finetuned-llama/halfinput/checkpoint-500/adapter_config.json\n/kaggle/input/finetuned-llama/halfinput/checkpoint-500/README.md\n/kaggle/input/finetuned-llama/halfinput/checkpoint-500/scheduler.pt\n/kaggle/input/finetuned-llama/halfinput/checkpoint-500/optimizer.pt\n/kaggle/input/finetuned-llama/halfinput/checkpoint-500/rng_state.pth\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1000/adapter_model.safetensors\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1000/trainer_state.json\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1000/training_args.bin\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1000/adapter_config.json\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1000/README.md\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1000/scheduler.pt\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1000/optimizer.pt\n/kaggle/input/finetuned-llama/halfinput/checkpoint-1000/rng_state.pth\n/kaggle/input/fragen-csvs/Final_CSV/Fragen DB.CSV\n/kaggle/input/fragen-csvs/Final_CSV/Fragen Big Data.CSV\n/kaggle/input/fragen-csvs/Final_CSV/Fragen ML.csv\n/kaggle/input/fragen-csvs/Final_CSV/Fragen BK.CSV\n/kaggle/input/fast-text/wiki-news-300d-1M-subword.vec\n","output_type":"stream"}]},{"cell_type":"code","source":"# load FastText\nmodel_word = KeyedVectors.load_word2vec_format('/kaggle/input/fast-text/wiki-news-300d-1M-subword.vec', binary=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T12:43:20.488395Z","iopub.execute_input":"2024-01-19T12:43:20.488696Z","iopub.status.idle":"2024-01-19T12:48:07.186286Z","shell.execute_reply.started":"2024-01-19T12:43:20.488669Z","shell.execute_reply":"2024-01-19T12:48:07.185393Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Creating the final data frame with the results\nfinal_table = pd.DataFrame(columns=[\"Question\", \"Answer\", \"Answer1\", \"Answer2\", \"Result\", \"similarity_1\", \"similarity_2\",\"similarity_winner\", \"explenation\"])","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:00.981780Z","iopub.execute_input":"2024-01-19T15:04:00.982177Z","iopub.status.idle":"2024-01-19T15:04:00.988559Z","shell.execute_reply.started":"2024-01-19T15:04:00.982143Z","shell.execute_reply":"2024-01-19T15:04:00.987602Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"final_table","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:03.773029Z","iopub.execute_input":"2024-01-19T15:04:03.773999Z","iopub.status.idle":"2024-01-19T15:04:03.783456Z","shell.execute_reply.started":"2024-01-19T15:04:03.773953Z","shell.execute_reply":"2024-01-19T15:04:03.782625Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Question, Answer, Answer1, Answer2, Result, similarity_1, similarity_2, similarity_winner, explenation]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n      <th>Answer1</th>\n      <th>Answer2</th>\n      <th>Result</th>\n      <th>similarity_1</th>\n      <th>similarity_2</th>\n      <th>similarity_winner</th>\n      <th>explenation</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# convert text into an average vector\ndef text_to_vector(text, model):\n    words = text.split()\n    word_vectors = [model[word] for word in words if word in model]\n    if not word_vectors:\n        return np.zeros(model.vector_size)\n    return np.mean(word_vectors, axis=0)\n\n# Calculating the cosine similarity between two texts\ndef cosine_similarity_texts(text1, text2, model):\n    vector1 = text_to_vector(text1, model)\n    vector2 = text_to_vector(text2, model)\n    return cosine_similarity([vector1], [vector2])[0][0]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T12:48:07.234570Z","iopub.execute_input":"2024-01-19T12:48:07.234813Z","iopub.status.idle":"2024-01-19T12:48:07.241014Z","shell.execute_reply.started":"2024-01-19T12:48:07.234792Z","shell.execute_reply":"2024-01-19T12:48:07.240170Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"raw","source":"# Loading Secrets f\n","metadata":{"execution":{"iopub.status.busy":"2024-01-19T12:48:07.242129Z","iopub.execute_input":"2024-01-19T12:48:07.242405Z","iopub.status.idle":"2024-01-19T12:48:07.610467Z","shell.execute_reply.started":"2024-01-19T12:48:07.242382Z","shell.execute_reply":"2024-01-19T12:48:07.609711Z"}}},{"cell_type":"code","source":"# Loading Secrets (API Key from OpenAi) from UserSecretsClient \nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"api_key\")\nclient = OpenAI(api_key=api_key)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load questions with sample answers\nquestions = pd.read_csv(\"/kaggle/input/ds-data/Fragen DS.csv\",encoding='ISO-8859-1', sep=\";\") ","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:13.196470Z","iopub.execute_input":"2024-01-19T15:04:13.196808Z","iopub.status.idle":"2024-01-19T15:04:13.203587Z","shell.execute_reply.started":"2024-01-19T15:04:13.196780Z","shell.execute_reply":"2024-01-19T15:04:13.202814Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"questions.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:15.740704Z","iopub.execute_input":"2024-01-19T15:04:15.741610Z","iopub.status.idle":"2024-01-19T15:04:15.750793Z","shell.execute_reply.started":"2024-01-19T15:04:15.741574Z","shell.execute_reply":"2024-01-19T15:04:15.749743Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"                                            Question  \\\n0  What are the three pillars of Data Science as ...   \n1  What is the central goal of Data Science as de...   \n2  What are the key stages and participants in th...   \n3  What are some examples of methodologies and te...   \n4  What are the key components of Data Science fr...   \n\n                                              Answer  \n0  The three pillars of Data Science are Data Sci...  \n1  The central goal of Data Science is knowledge ...  \n2  The Data Science process model includes six ph...  \n3  In the Data Science process, methodologies inc...  \n4  From an IT perspective, Data Science is an int...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are the three pillars of Data Science as ...</td>\n      <td>The three pillars of Data Science are Data Sci...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the central goal of Data Science as de...</td>\n      <td>The central goal of Data Science is knowledge ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What are the key stages and participants in th...</td>\n      <td>The Data Science process model includes six ph...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What are some examples of methodologies and te...</td>\n      <td>In the Data Science process, methodologies inc...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What are the key components of Data Science fr...</td>\n      <td>From an IT perspective, Data Science is an int...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"questions.shape[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:21.977027Z","iopub.execute_input":"2024-01-19T15:04:21.977647Z","iopub.status.idle":"2024-01-19T15:04:21.983346Z","shell.execute_reply.started":"2024-01-19T15:04:21.977613Z","shell.execute_reply":"2024-01-19T15:04:21.982379Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}]},{"cell_type":"markdown","source":"### Tokenizer","metadata":{}},{"cell_type":"code","source":"# Base model id\nmodel_id = \"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\"\n# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\n#count max tokens of the sample answeres\nlen_list = []\nfor line in range(questions.shape[0]):\n    text = questions[\"Answer\"][line]\n    # Tokenisierung des Textes\n    tokens = tokenizer.tokenize(text)\n    # Anzahl der Tokens\n    token_count = len(tokens)\n    len_list.append(token_count)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:29.862672Z","iopub.execute_input":"2024-01-19T15:04:29.863011Z","iopub.status.idle":"2024-01-19T15:04:29.985335Z","shell.execute_reply.started":"2024-01-19T15:04:29.862984Z","shell.execute_reply":"2024-01-19T15:04:29.984469Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"max_tokens_for_model = max(len_list)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:32.787078Z","iopub.execute_input":"2024-01-19T15:04:32.787824Z","iopub.status.idle":"2024-01-19T15:04:32.791904Z","shell.execute_reply.started":"2024-01-19T15:04:32.787792Z","shell.execute_reply":"2024-01-19T15:04:32.790939Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"max_tokens_for_model","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:35.026090Z","iopub.execute_input":"2024-01-19T15:04:35.026948Z","iopub.status.idle":"2024-01-19T15:04:35.032382Z","shell.execute_reply.started":"2024-01-19T15:04:35.026916Z","shell.execute_reply":"2024-01-19T15:04:35.031433Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"176"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load Llama 2 7B Base","metadata":{}},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\n\nmodel = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    tokenizer=tokenizer\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T12:48:07.830694Z","iopub.execute_input":"2024-01-19T12:48:07.830941Z","iopub.status.idle":"2024-01-19T12:51:28.228392Z","shell.execute_reply.started":"2024-01-19T12:48:07.830919Z","shell.execute_reply":"2024-01-19T12:51:28.227617Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39c1c893afc9431daa0f9ddaba0cd74a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:393: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:398: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Llama Finetuned Load","metadata":{}},{"cell_type":"code","source":"model_id_2 = \"/kaggle/input/finetuned-llama/model_7_4Entries\"\n\nmodel_2 = AutoModelForCausalLM.from_pretrained(model_id_2, quantization_config=bnb_config, device_map={\"\":0})\n\npipeline2 = transformers.pipeline(\n    \"text-generation\",\n    model=model_2,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    tokenizer=tokenizer\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T12:51:28.229508Z","iopub.execute_input":"2024-01-19T12:51:28.229804Z","iopub.status.idle":"2024-01-19T12:51:36.873005Z","shell.execute_reply.started":"2024-01-19T12:51:28.229778Z","shell.execute_reply":"2024-01-19T12:51:36.872165Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68cdde2e2b38496babf299f64a78daca"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:393: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:398: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Autoeval","metadata":{}},{"cell_type":"code","source":"for line in tqdm(range(questions.shape[0]), desc=\"Verarbeite Fragen\"):\n    question = questions[\"Question\"][line]\n    answer = questions[\"Answer\"][line]\n    #Llama 2 Base\n    sequences = pipeline(\n       f'[INST]{question}[/INST]',\n       do_sample=True,\n       top_k=10,\n       num_return_sequences=1,\n       eos_token_id=tokenizer.eos_token_id,\n       max_length=max_tokens_for_model,\n    )\n    answer1 = \"\"\n    for seq in sequences:\n       answer1+=seq['generated_text']\n    answer1 = answer1.split(\"[/INST]  \", 1)[-1]\n    #Llama 2 Finetuned \n    sequences2 = pipeline2(\n       f'[INST]{question}[/INST]',\n       do_sample=True,\n       top_k=10,\n       num_return_sequences=1,\n       eos_token_id=tokenizer.eos_token_id,\n       max_length=max_tokens_for_model,\n    )\n    answer2 = \"\"\n    for seq in sequences2:\n       answer2+=seq['generated_text']\n    answer2 = answer2.split(\"[/INST]  \", 1)[-1]\n\n    # Random generator\n    zufallszahl = random.choice([0, 1])\n    answers= [answer1, answer2]\n\n    if zufallszahl == 0:\n        zufallszahl2 = 1\n    else:\n        zufallszahl2 = 0\n\n    auswertung = client.chat.completions.create(\n        model=\"gpt-4-1106-preview\",\n        messages=[{\"role\": \"system\", \"content\": \"I'll now give you a question, the sample solution to this question and 2 other answers. Decide based on the context of the model solution which of the two answers is better and only output “1” or “2” and after that a short explanation why!\"},\n                  {\"role\": \"user\", \"content\": f\"{question} \\n sample {answer} \\n 1. Answer: {answers[zufallszahl]} \\n 2. Answer: {answers[zufallszahl2]}\"}]\n    )\n    explain = auswertung.choices[0].message.content\n    better_answer_llm = int(explain[0])\n    # similarity for each row\n    cos_1 = cosine_similarity_texts(answer, answer1, model_word)\n    cos_2 = cosine_similarity_texts(answer, answer2, model_word)\n    if cos_1 > cos_2:\n        better_answer = 1\n    else:\n        better_answer = 2\n    # Undo random order\n    if zufallszahl == 1:\n        if int(better_answer_llm) == 1:\n            better_answer_llm = 2\n        else:\n            better_answer_llm = 1\n    neue_zeile = [question, answer, answer1, answer2, better_answer_llm,cos_1, cos_2,better_answer,explain]\n\n    final_table.loc[len(final_table)] = neue_zeile","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:45.988882Z","iopub.execute_input":"2024-01-19T15:04:45.989678Z","iopub.status.idle":"2024-01-19T15:19:45.793920Z","shell.execute_reply.started":"2024-01-19T15:04:45.989642Z","shell.execute_reply":"2024-01-19T15:19:45.792984Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stderr","text":"Verarbeite Fragen:   0%|          | 0/20 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:   5%|▌         | 1/20 [00:48<15:17, 48.31s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  10%|█         | 2/20 [01:30<13:27, 44.87s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  15%|█▌        | 3/20 [02:13<12:26, 43.93s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  20%|██        | 4/20 [03:01<12:08, 45.50s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  25%|██▌       | 5/20 [03:48<11:31, 46.07s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  30%|███       | 6/20 [04:35<10:49, 46.39s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  35%|███▌      | 7/20 [05:13<09:25, 43.50s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  40%|████      | 8/20 [05:50<08:18, 41.51s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  45%|████▌     | 9/20 [06:34<07:46, 42.37s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  50%|█████     | 10/20 [07:24<07:25, 44.56s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  55%|█████▌    | 11/20 [08:06<06:35, 43.94s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  60%|██████    | 12/20 [08:44<05:36, 42.03s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  65%|██████▌   | 13/20 [09:30<05:03, 43.33s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  70%|███████   | 14/20 [10:12<04:16, 42.78s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  75%|███████▌  | 15/20 [11:03<03:46, 45.29s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  80%|████████  | 16/20 [11:41<02:53, 43.27s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  85%|████████▌ | 17/20 [12:41<02:24, 48.27s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  90%|█████████ | 18/20 [13:30<01:37, 48.52s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen:  95%|█████████▌| 19/20 [14:13<00:46, 46.85s/it]/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1123: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nVerarbeite Fragen: 100%|██████████| 20/20 [14:59<00:00, 44.99s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"# show finale table\nfinal_table","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:19:54.185479Z","iopub.execute_input":"2024-01-19T15:19:54.185823Z","iopub.status.idle":"2024-01-19T15:19:54.204456Z","shell.execute_reply.started":"2024-01-19T15:19:54.185797Z","shell.execute_reply":"2024-01-19T15:19:54.203513Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"                                             Question  \\\n0   What are the three pillars of Data Science as ...   \n1   What is the central goal of Data Science as de...   \n2   What are the key stages and participants in th...   \n3   What are some examples of methodologies and te...   \n4   What are the key components of Data Science fr...   \n5   How does Data Science approach knowledge disco...   \n6   What are the three classes of defects in data ...   \n7   What are the key subprocesses in data transfor...   \n8   What are the methodologies and types of learni...   \n9   How is Machine Learning (ML) characterized in ...   \n10  What is the significance of Machine Learning (...   \n11  What are the basics of hardware and software r...   \n12  What are the key steps and considerations in v...   \n13  How is TensorFlow used in Python for Data Scie...   \n14  How is Mean Squared Error (MSE) used to valida...   \n15  What is the Bias-Variance Trade-Off in model v...   \n16         What is Linear Regression in Data Science?   \n17        What are Association Rules in Data Science?   \n18                     What is the Apriori Algorithm?   \n19            What are some types of cluster methods?   \n\n                                               Answer  \\\n0   The three pillars of Data Science are Data Sci...   \n1   The central goal of Data Science is knowledge ...   \n2   The Data Science process model includes six ph...   \n3   In the Data Science process, methodologies inc...   \n4   From an IT perspective, Data Science is an int...   \n5   From a conceptual-algorithmic perspective, Dat...   \n6   The three classes of defects in data preproces...   \n7   Key subprocesses in data transformation includ...   \n8   Data Mining methodologies include Machine & De...   \n9   Machine Learning (ML) is the science and metho...   \n10  Machine Learning (ML) is a central area in dat...   \n11  For Data Science, a standard notebook or PC is...   \n12  Validating machine learning models involves tr...   \n13  TensorFlow is a prominent library used in Pyth...   \n14  Mean Squared Error (MSE) is a key metric for v...   \n15  The Bias-Variance Trade-Off is a fundamental c...   \n16  Linear Regression is a statistical method used...   \n17  Association Rules in Data Science are used to ...   \n18  The Apriori Algorithm is used to discover freq...   \n19  Cluster analysis methods include partitioning,...   \n\n                                              Answer1  \\\n0   In the Data Science lecture, the three pillars...   \n1   The central goal of Data Science, as described...   \n2   The Data Science process model is a standardiz...   \n3   Data Science is a multidisciplinary field that...   \n4   From an IT perspective, the key components of ...   \n5   Data Science is an interdisciplinary field tha...   \n6   In data preprocessing, there are three main cl...   \n7   Data transformation is a crucial step in the d...   \n8   Data mining, as an interdisciplinary field tha...   \n9   Machine Learning (ML) is a subfield of Data Sc...   \n10  Machine Learning (ML) is a critical component ...   \n11  Data Science is a field that combines computat...   \n12  Validating machine learning models is a critic...   \n13  TensorFlow is a popular open-source deep learn...   \n14  Mean Squared Error (MSE) is a commonly used me...   \n15  The bias-variance trade-off is a fundamental c...   \n16  Linear regression is a fundamental data scienc...   \n17  Association rules are a technique used in data...   \n18  The Apriori algorithm is a popular algorithm u...   \n19  There are several types of cluster methods, so...   \n\n                                              Answer2  Result  similarity_1  \\\n0   The three pillars of Data Science, as outlined...       1      0.921012   \n1   The central goal of Data Science, as described...       2      0.959813   \n2   The Data Science Process Model is a common mod...       2      0.818927   \n3   Here are some examples of methodologies and te...       2      0.841836   \n4   From an IT perspective, Data Science projects ...       2      0.961563   \n5   Data Science approaches knowledge discovery an...       2      0.941162   \n6   Classification of Defects in Data Transformati...       2      0.887036   \n7   The key subprocesses in data transformation fo...       1      0.897222   \n8   Data mining involves statistical models and al...       2      0.763194   \n9   Machine Learning (ML) is a subfield of Data Sc...       1      0.962102   \n10  Machine Learning (ML) is a crucial component o...       1      0.925568   \n11  Python is a widely-used programming language i...       2      0.838586   \n12  Model validation is an important part of the m...       1      0.961665   \n13  TensorFlow is a popular open-source machine le...       1      0.949816   \n14  Mean Squared Error (MSE) is a commonly used lo...       1      0.975802   \n15  The bias-variance trade-off is a fundamental i...       1      0.966436   \n16  Linear regression is a type of regression anal...       2      0.981837   \n17  Association Rules in Data Science:   - Associa...       2      0.924527   \n18  The Apriori Algorithm is a classical algorithm...       1      0.961106   \n19  There are several types of cluster methods, in...       2      0.920478   \n\n    similarity_2  similarity_winner  \\\n0       0.918245                  1   \n1       0.937084                  1   \n2       0.610425                  1   \n3       0.889097                  2   \n4       0.642676                  1   \n5       0.860103                  1   \n6       0.646392                  1   \n7       0.406597                  1   \n8       0.710218                  1   \n9       0.962690                  2   \n10      0.935399                  2   \n11      0.905018                  2   \n12      0.961154                  1   \n13      0.957038                  2   \n14      0.770003                  1   \n15      0.975397                  2   \n16      0.974735                  1   \n17      0.917741                  1   \n18      0.770289                  1   \n19      0.866071                  1   \n\n                                          explenation  \n0   1\\n\\nThe first answer aligns more closely with...  \n1   1\\n\\nThe first answer is better because it cap...  \n2   1\\n\\nThe first answer provides a more structur...  \n3   1\\n\\nThe first answer is better because it pro...  \n4   1\\n\\nThe first answer is better in the given c...  \n5   1\\n\\nThe first answer provides a more structur...  \n6   1\\n\\nThe first answer goes more in-depth into ...  \n7   2\\n\\nThe second answer aligns more closely wit...  \n8   1\\n\\nThe first answer is better as it remains ...  \n9   2\\n\\nAnswer 2 is better because it aligns clos...  \n10  1\\n\\nThe first answer is better because it not...  \n11  2\\n\\nThe second answer provides a more detaile...  \n12  1\\n\\nAnswer 1 is better because it directly al...  \n13  1\\n\\nThe first answer is better because it pro...  \n14  1\\n\\nThe first answer is better because it is ...  \n15  1\\n\\nAnswer 1 is better because it more direct...  \n16  1\\n\\nAnswer 1 is better because it extends the...  \n17  1\\n\\nThe first answer is better because it pro...  \n18  1\\n\\nThe first answer is better because it cor...  \n19  1\\n\\nThe first answer provides a seemingly non...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Answer</th>\n      <th>Answer1</th>\n      <th>Answer2</th>\n      <th>Result</th>\n      <th>similarity_1</th>\n      <th>similarity_2</th>\n      <th>similarity_winner</th>\n      <th>explenation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What are the three pillars of Data Science as ...</td>\n      <td>The three pillars of Data Science are Data Sci...</td>\n      <td>In the Data Science lecture, the three pillars...</td>\n      <td>The three pillars of Data Science, as outlined...</td>\n      <td>1</td>\n      <td>0.921012</td>\n      <td>0.918245</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer aligns more closely with...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the central goal of Data Science as de...</td>\n      <td>The central goal of Data Science is knowledge ...</td>\n      <td>The central goal of Data Science, as described...</td>\n      <td>The central goal of Data Science, as described...</td>\n      <td>2</td>\n      <td>0.959813</td>\n      <td>0.937084</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer is better because it cap...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What are the key stages and participants in th...</td>\n      <td>The Data Science process model includes six ph...</td>\n      <td>The Data Science process model is a standardiz...</td>\n      <td>The Data Science Process Model is a common mod...</td>\n      <td>2</td>\n      <td>0.818927</td>\n      <td>0.610425</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer provides a more structur...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What are some examples of methodologies and te...</td>\n      <td>In the Data Science process, methodologies inc...</td>\n      <td>Data Science is a multidisciplinary field that...</td>\n      <td>Here are some examples of methodologies and te...</td>\n      <td>2</td>\n      <td>0.841836</td>\n      <td>0.889097</td>\n      <td>2</td>\n      <td>1\\n\\nThe first answer is better because it pro...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What are the key components of Data Science fr...</td>\n      <td>From an IT perspective, Data Science is an int...</td>\n      <td>From an IT perspective, the key components of ...</td>\n      <td>From an IT perspective, Data Science projects ...</td>\n      <td>2</td>\n      <td>0.961563</td>\n      <td>0.642676</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer is better in the given c...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>How does Data Science approach knowledge disco...</td>\n      <td>From a conceptual-algorithmic perspective, Dat...</td>\n      <td>Data Science is an interdisciplinary field tha...</td>\n      <td>Data Science approaches knowledge discovery an...</td>\n      <td>2</td>\n      <td>0.941162</td>\n      <td>0.860103</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer provides a more structur...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>What are the three classes of defects in data ...</td>\n      <td>The three classes of defects in data preproces...</td>\n      <td>In data preprocessing, there are three main cl...</td>\n      <td>Classification of Defects in Data Transformati...</td>\n      <td>2</td>\n      <td>0.887036</td>\n      <td>0.646392</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer goes more in-depth into ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>What are the key subprocesses in data transfor...</td>\n      <td>Key subprocesses in data transformation includ...</td>\n      <td>Data transformation is a crucial step in the d...</td>\n      <td>The key subprocesses in data transformation fo...</td>\n      <td>1</td>\n      <td>0.897222</td>\n      <td>0.406597</td>\n      <td>1</td>\n      <td>2\\n\\nThe second answer aligns more closely wit...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>What are the methodologies and types of learni...</td>\n      <td>Data Mining methodologies include Machine &amp; De...</td>\n      <td>Data mining, as an interdisciplinary field tha...</td>\n      <td>Data mining involves statistical models and al...</td>\n      <td>2</td>\n      <td>0.763194</td>\n      <td>0.710218</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer is better as it remains ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>How is Machine Learning (ML) characterized in ...</td>\n      <td>Machine Learning (ML) is the science and metho...</td>\n      <td>Machine Learning (ML) is a subfield of Data Sc...</td>\n      <td>Machine Learning (ML) is a subfield of Data Sc...</td>\n      <td>1</td>\n      <td>0.962102</td>\n      <td>0.962690</td>\n      <td>2</td>\n      <td>2\\n\\nAnswer 2 is better because it aligns clos...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>What is the significance of Machine Learning (...</td>\n      <td>Machine Learning (ML) is a central area in dat...</td>\n      <td>Machine Learning (ML) is a critical component ...</td>\n      <td>Machine Learning (ML) is a crucial component o...</td>\n      <td>1</td>\n      <td>0.925568</td>\n      <td>0.935399</td>\n      <td>2</td>\n      <td>1\\n\\nThe first answer is better because it not...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>What are the basics of hardware and software r...</td>\n      <td>For Data Science, a standard notebook or PC is...</td>\n      <td>Data Science is a field that combines computat...</td>\n      <td>Python is a widely-used programming language i...</td>\n      <td>2</td>\n      <td>0.838586</td>\n      <td>0.905018</td>\n      <td>2</td>\n      <td>2\\n\\nThe second answer provides a more detaile...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>What are the key steps and considerations in v...</td>\n      <td>Validating machine learning models involves tr...</td>\n      <td>Validating machine learning models is a critic...</td>\n      <td>Model validation is an important part of the m...</td>\n      <td>1</td>\n      <td>0.961665</td>\n      <td>0.961154</td>\n      <td>1</td>\n      <td>1\\n\\nAnswer 1 is better because it directly al...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>How is TensorFlow used in Python for Data Scie...</td>\n      <td>TensorFlow is a prominent library used in Pyth...</td>\n      <td>TensorFlow is a popular open-source deep learn...</td>\n      <td>TensorFlow is a popular open-source machine le...</td>\n      <td>1</td>\n      <td>0.949816</td>\n      <td>0.957038</td>\n      <td>2</td>\n      <td>1\\n\\nThe first answer is better because it pro...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>How is Mean Squared Error (MSE) used to valida...</td>\n      <td>Mean Squared Error (MSE) is a key metric for v...</td>\n      <td>Mean Squared Error (MSE) is a commonly used me...</td>\n      <td>Mean Squared Error (MSE) is a commonly used lo...</td>\n      <td>1</td>\n      <td>0.975802</td>\n      <td>0.770003</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer is better because it is ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>What is the Bias-Variance Trade-Off in model v...</td>\n      <td>The Bias-Variance Trade-Off is a fundamental c...</td>\n      <td>The bias-variance trade-off is a fundamental c...</td>\n      <td>The bias-variance trade-off is a fundamental i...</td>\n      <td>1</td>\n      <td>0.966436</td>\n      <td>0.975397</td>\n      <td>2</td>\n      <td>1\\n\\nAnswer 1 is better because it more direct...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>What is Linear Regression in Data Science?</td>\n      <td>Linear Regression is a statistical method used...</td>\n      <td>Linear regression is a fundamental data scienc...</td>\n      <td>Linear regression is a type of regression anal...</td>\n      <td>2</td>\n      <td>0.981837</td>\n      <td>0.974735</td>\n      <td>1</td>\n      <td>1\\n\\nAnswer 1 is better because it extends the...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>What are Association Rules in Data Science?</td>\n      <td>Association Rules in Data Science are used to ...</td>\n      <td>Association rules are a technique used in data...</td>\n      <td>Association Rules in Data Science:   - Associa...</td>\n      <td>2</td>\n      <td>0.924527</td>\n      <td>0.917741</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer is better because it pro...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>What is the Apriori Algorithm?</td>\n      <td>The Apriori Algorithm is used to discover freq...</td>\n      <td>The Apriori algorithm is a popular algorithm u...</td>\n      <td>The Apriori Algorithm is a classical algorithm...</td>\n      <td>1</td>\n      <td>0.961106</td>\n      <td>0.770289</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer is better because it cor...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>What are some types of cluster methods?</td>\n      <td>Cluster analysis methods include partitioning,...</td>\n      <td>There are several types of cluster methods, so...</td>\n      <td>There are several types of cluster methods, in...</td>\n      <td>2</td>\n      <td>0.920478</td>\n      <td>0.866071</td>\n      <td>1</td>\n      <td>1\\n\\nThe first answer provides a seemingly non...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Save DataFrame as CSV file\nfile_name = 'Final_DS_Eval.csv'\nfinal_table.to_csv(file_name, index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:20:33.921098Z","iopub.execute_input":"2024-01-19T15:20:33.921468Z","iopub.status.idle":"2024-01-19T15:20:33.930238Z","shell.execute_reply.started":"2024-01-19T15:20:33.921440Z","shell.execute_reply":"2024-01-19T15:20:33.929276Z"},"trusted":true},"execution_count":75,"outputs":[]}]}