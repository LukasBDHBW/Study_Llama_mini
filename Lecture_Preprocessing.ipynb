{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "import pytesseract\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key and path variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key from a config file \n",
    "config = configparser.ConfigParser()\n",
    "config.read('../Edu_Llama/config.ini')\n",
    "api_key = config['openai']['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the PDF file\n",
    "pdf = '001 Querschnittsfunktion_Klausur'\n",
    "pdf_path = f'../../Geschäftsprozessmanagement/PDFs/{pdf}.pdf'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picture control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes it possible to recognize and display images in the PDF, and also writes the maximum page numbers into a list and the pages on which images are present.\n",
    "# If the tool does not recognize any images, a list with all the desired images must be created manually\n",
    "def extract_and_plot_images(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    num_pages = len(doc)\n",
    "    images=[]\n",
    "    pages=[]\n",
    "    for i in range(428,len(doc)):\n",
    "        page = doc.load_page(i)\n",
    "\n",
    "        # Extract images on the page\n",
    "        for img in page.get_images(full=True):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            # View image\n",
    "            plt.imshow(image)\n",
    "            print(f\"Seite: {i+1}\")\n",
    "            pages.append(i+1)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    pages = list(set(pages))\n",
    "    doc.close()\n",
    "    return pages,num_pages\n",
    "    \t\n",
    "pages,num_pages = extract_and_plot_images(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment In case a list with the images needs to be created manually\n",
    "#pages=[428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the PIL image\n",
    "def encode_pil_image(pil_image):\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function extracts images with OCR or with direct reading of the text from a start to an end page\n",
    "def extract_text_from_range(file_path, start_page, end_page,OCR = ''):\n",
    "    if OCR == 'OCR':\n",
    "        extracted_texts = []\n",
    "        for image_num in tqdm(range(start_page+1, end_page), desc='Texextraktion_OCR'):\n",
    "            images = convert_from_path(file_path, first_page=image_num, last_page=image_num)\n",
    "            extracted_text = pytesseract.image_to_string(images[0])\n",
    "            extracted_texts.append(extracted_text)\n",
    "        extracted_text = \" \".join(extracted_texts)\n",
    "\n",
    "    else:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            extracted_text = ''\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "\n",
    "            #Check whether the page numbers are within the valid range\n",
    "            if start_page < 0 or end_page > num_pages or start_page > end_page:\n",
    "                return \"Ungültiger Seitenbereich.\"\n",
    "\n",
    "            for page_number in tqdm(range(start_page, end_page), desc='Texextraktion'):\n",
    "                page = pdf_reader.pages[page_number]\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    extracted_text += page_text + '\\n'\n",
    "                else:\n",
    "                    extracted_text += f'Kein Text auf Seite {page_number + 1}\\n'\n",
    "        \n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts entire pages as an image from the PDF\n",
    "def extract_images_from_pdf(file_path, page_number):\n",
    "    print(\"Extrahiere Bilder...\")\n",
    "    images = convert_from_path(file_path, first_page=page_number, last_page=page_number)\n",
    "    \n",
    "    bild=images[0]\n",
    "    if bild.size[0]>=600:\n",
    "        skale=600\n",
    "    else:\n",
    "        skale=bild.size[0]\n",
    "    # Define new size\n",
    "    neue_groesse = (skale, int((bild.size[1]/bild.size[0])*skale))\n",
    "\n",
    "    # Scale image\n",
    "    skaliertes_bild = bild.resize(neue_groesse)\n",
    "\n",
    "    return skaliertes_bild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picture to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes images from the lecture page and converts them into a textual image description\n",
    "def image_to_text(pil_image):\n",
    "  print(\"Image to text\")\n",
    "  base64_image = encode_pil_image(pil_image)\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"model\": \"gpt-4-vision-preview\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Beschreibe den inhalt des Bildes?\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "  }\n",
    "\n",
    "  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "  return response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_pipeline(file_path, pages, num_pages,OCR = ''):\n",
    "    final_text = ''\n",
    "    page_old = 0\n",
    "    # Check whether images have also been entered into the list\n",
    "    if len(pages) == 0:\n",
    "        final_text = extract_text_from_range(file_path, 0, num_pages,OCR = OCR)\n",
    "    else:\n",
    "        for page in tqdm(pages, desc='Processing Pages'):\n",
    "            liste = list(range(num_pages))[page_old:page]\n",
    "            if page_old != page + 1:\n",
    "                text = extract_text_from_range(file_path, liste[0], liste[-1],OCR = OCR)\n",
    "                final_text += text\n",
    "            image = extract_images_from_pdf(file_path, page)\n",
    "            img_text = image_to_text(image)\n",
    "            final_text += f'Bild:{img_text}'\n",
    "            page_old = page\n",
    "            if page == pages[-1] and page != num_pages:\n",
    "                text = extract_text_from_range(file_path, page+1, num_pages)\n",
    "                final_text += text\n",
    "    \n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Texextraktion: 100%|██████████| 37/37 [00:00<00:00, 78.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# If PDF cannot be read normally, specify OCR=\"OCR\" as the fourth parameter\n",
    "text = pre_process_pipeline(pdf_path,pages,num_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the preprocessed lecture text\n",
    "with open(f'../../{pdf}.txt', 'w') as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "necessary because OpenAI API of GPT3.5 can only process 4096 tokens per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the extracted text file of the lecture\n",
    "with open(f'../Vorlesungen/{pdf}.txt', 'r') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_token_content=num_tokens_from_string(content, 'gpt-3.5-turbo')\n",
    "n= math.ceil(num_token_content/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences_into_equal_parts(content, n):\n",
    "    # Split the text into sentences\n",
    "    sentences = content.split('. ')\n",
    "    \n",
    "    # Number of sentences\n",
    "    total_sentences = len(sentences)\n",
    "\n",
    "    # Number of sentences per part\n",
    "    sentences_per_part = max(1, total_sentences // n)\n",
    "\n",
    "    parts = []\n",
    "    current_part = []\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        current_part.append(sentence)\n",
    "        \n",
    "        # Check if current part is full or it's the last sentence\n",
    "        if len(current_part) == sentences_per_part or i == total_sentences - 1:\n",
    "            parts.append(' '.join(current_part))\n",
    "            current_part = []\n",
    "\n",
    "    return parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of text pieces\n",
    "string_parts = split_sentences_into_equal_parts(content, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API call and system prompt for translation\n",
    "def chat_with_gpt(prompt):\n",
    "    client = OpenAI(api_key=api_key,)\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.Translate all the texts you get in english language and write all formulas in latex syntax.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write translation to file\n",
    "for string in tqdm(string_parts, desc='Translating...'):\n",
    "    response = chat_with_gpt(string)\n",
    "    with open(f'../Vorlesungen/{pdf}_eng.txt', \"a\") as file:\n",
    "        file.write(response)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
