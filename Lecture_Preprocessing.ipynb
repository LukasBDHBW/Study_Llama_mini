{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "import pytesseract\n",
    "import base64\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "from langdetect import detect\n",
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "import configparser\n",
    "from openai import OpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key and path variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../Edu_Llama/config.ini')\n",
    "api_key = config['openai']['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pfad zur PDF-Datei\n",
    "pdf = 'ML_fundamentals'\n",
    "pdf_path = f'C:/Users/a829727/OneDrive - Atos/Dokumente/Uni/Semester 5/NLP/Vorlesungen/{pdf}.pdf'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Picture control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_plot_images(pdf_path):\n",
    "    # PDF-Dokument öffnen\n",
    "    doc = fitz.open(pdf_path)\n",
    "    # Ermittle die Anzahl der Seiten\n",
    "    num_pages = len(doc)\n",
    "    images=[]\n",
    "    pages=[]\n",
    "    # Durch jede Seite des PDFs gehen\n",
    "    for i in range(428,len(doc)):\n",
    "        page = doc.load_page(i)\n",
    "\n",
    "        # Bilder auf der Seite extrahieren\n",
    "        for img in page.get_images(full=True):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "\n",
    "            # Bild mit PIL verarbeiten\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            images.append(image)\n",
    "            # Bild anzeigen\n",
    "            plt.imshow(image)\n",
    "            print(f\"Seite: {i+1}\")\n",
    "            pages.append(i+1)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    pages = list(set(pages))\n",
    "    doc.close()\n",
    "    return images,pages,num_pages\n",
    "    \t\n",
    "images,pages,num_pages = extract_and_plot_images(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, um das PIL-Bild zu kodieren\n",
    "def encode_pil_image(pil_image):\n",
    "    buffered = BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_range(file_path, start_page, end_page,OCR = ''):\n",
    "    if OCR == 'OCR':\n",
    "        extracted_texts = []\n",
    "        for image_num in tqdm(range(start_page+1, end_page), desc='Texextraktion_OCR'):\n",
    "            images = convert_from_path(file_path, first_page=image_num, last_page=image_num)\n",
    "            extracted_text = pytesseract.image_to_string(images[0])\n",
    "            extracted_texts.append(extracted_text)\n",
    "        extracted_text = \" \".join(extracted_texts)\n",
    "\n",
    "    else:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            extracted_text = ''\n",
    "\n",
    "            # Anzahl der Seiten in der PDF-Datei bestimmen\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "\n",
    "            # Überprüfung, ob die Seitenzahlen im gültigen Bereich liegen\n",
    "            if start_page < 0 or end_page > num_pages or start_page > end_page:\n",
    "                return \"Ungültiger Seitenbereich.\"\n",
    "\n",
    "            for page_number in tqdm(range(start_page, end_page), desc='Texextraktion'):\n",
    "                page = pdf_reader.pages[page_number]\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    extracted_text += page_text + '\\n'\n",
    "                else:\n",
    "                    extracted_text += f'Kein Text auf Seite {page_number + 1}\\n'\n",
    "        \n",
    "    return extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_images_from_pdf(file_path, page_number):\n",
    "    print(\"Extrahiere Bilder...\")\n",
    "    images = convert_from_path(file_path, first_page=page_number, last_page=page_number)\n",
    "    \n",
    "    bild=images[0]\n",
    "    if bild.size[0]>=600:\n",
    "        skale=600\n",
    "    else:\n",
    "        skale=bild.size[0]\n",
    "    # Neue Größe definieren \n",
    "    neue_groesse = (skale, int((bild.size[1]/bild.size[0])*skale))\n",
    "\n",
    "    # Bild skalieren\n",
    "    skaliertes_bild = bild.resize(neue_groesse)\n",
    "\n",
    "    return skaliertes_bild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picture to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the base64 string\n",
    "def image_to_text(pil_image):\n",
    "  print(\"Image to text\")\n",
    "  base64_image = encode_pil_image(pil_image)\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"model\": \"gpt-4-vision-preview\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Beschreibe den inhalt des Bildes?\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "  }\n",
    "\n",
    "  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "  return response.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_pipeline(file_path, pages, num_pages,OCR = ''):\n",
    "    final_text = ''\n",
    "    page_old = 0\n",
    "\n",
    "    if len(pages) == 0:\n",
    "        final_text = extract_text_from_range(file_path, 0, num_pages,OCR = OCR)\n",
    "    else:\n",
    "        for page in tqdm(pages, desc='Processing Pages'):\n",
    "            liste = list(range(num_pages))[page_old:page]\n",
    "            if page_old != page + 1:\n",
    "                text = extract_text_from_range(file_path, liste[0], liste[-1],OCR = OCR)\n",
    "                final_text += text\n",
    "            image = extract_images_from_pdf(file_path, page)\n",
    "            img_text = image_to_text(image)\n",
    "            final_text += f'Bild:{img_text}'\n",
    "            page_old = page\n",
    "            if page == pages[-1] and page != num_pages:\n",
    "                text = extract_text_from_range(file_path, page+1, num_pages)\n",
    "                final_text += text\n",
    "    \n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pre_process_pipeline(pdf_path,pages,num_pages,'OCR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the preprocessed lecture text\n",
    "with open(f'../../{pdf}.txt', 'w') as file:\n",
    "    file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufsplitten des Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Öffnen der Datei im Lesemodus\n",
    "with open(f'../Vorlesungen/{pdf}.txt', 'r') as file:\n",
    "    # Lesen des gesamten Inhalts der Datei\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_token_content=num_tokens_from_string(content, 'gpt-3.5-turbo')\n",
    "n=rounded_up = math.ceil(num_token_content/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences_into_equal_parts(content, n):\n",
    "    # Split the text into sentences\n",
    "    sentences = content.split('. ')\n",
    "    \n",
    "    # Number of sentences\n",
    "    total_sentences = len(sentences)\n",
    "\n",
    "    # Calculate the number of sentences per part\n",
    "    sentences_per_part = max(1, total_sentences // n)\n",
    "\n",
    "    # Initialize variables\n",
    "    parts = []\n",
    "    current_part = []\n",
    "\n",
    "    # Iterate over sentences and distribute them into parts\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        current_part.append(sentence)\n",
    "        \n",
    "        # Check if current part is full or it's the last sentence\n",
    "        if len(current_part) == sentences_per_part or i == total_sentences - 1:\n",
    "            # Join sentences and add to parts\n",
    "            parts.append(' '.join(current_part))\n",
    "            current_part = []\n",
    "\n",
    "    return parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_parts = split_sentences_into_equal_parts(content, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(string_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gpt(prompt):\n",
    "    client = OpenAI(api_key=api_key,)\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.Translate all the texts you get in english language and write all formulas in latex syntax.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text_eng=[]\n",
    "for string in tqdm(string_parts, desc='Chatting'):\n",
    "    response = chat_with_gpt(string)\n",
    "    with open(f'../Vorlesungen/{pdf}_eng.txt', \"a\") as file:\n",
    "        file.write(response)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../Vorlesungen/{pdf}_eng.txt', 'w') as file:\n",
    "    file.write(full_text_eng)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DTC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
