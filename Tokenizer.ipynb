{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Pfad zum Modell, ändern Sie dies entsprechend\n",
    "model_path = \"Ihr-Modellpfad-hier\"\n",
    "\n",
    "# Tokenizer initialisieren\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Padding-Token hinzufügen und die Token-Embedding-Größe anpassen\n",
    "tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "\n",
    "# LLaMA 2-Modell laden\n",
    "model = LlamaForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# Stellen Sie sicher, dass das Modell das Padding-Token kennt\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Pfad zur Ihrer Textdatei\n",
    "file_path = 'Ihr-Dateipfad-hier.txt'\n",
    "\n",
    "# Textdatei lesen\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Text tokenisieren\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Hier können Sie mit `inputs` weiterarbeiten\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
